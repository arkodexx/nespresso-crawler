# â˜•âš¡ Nespresso Product Crawler

A **fast, lightweight crawler for Nespresso.com** built with **pure Scrapy**, designed to extract structured product data at scale without browser automation.

Ideal for product analysis, pricing research, and catalog monitoring.

## ğŸ” Highlights

- âš¡ **High-speed product crawling** with async concurrency
- ğŸ§µ Efficient request scheduling optimized for catalog pages
- ğŸ§± **Fully populated product records** â€” no empty fields
- â™»ï¸ **Duplicate-safe pipelines** for clean datasets
- ğŸ“¦ Output formats: **CSV / JSON**

## ğŸ§° Tech Stack

- Python  
- Scrapy (no Selenium, no Playwright, minimal overhead)
- Scrapy-impersonate

## ğŸ“¥ Installation & Usage

```bash
git clone https://github.com/arkodexx/nespresso-crawler.git
cd nespresso-crawler
pip install -r requirements.txt
scrapy crawl crawler -o data.json
or
scrapy crawl crawler -o data.csv
